{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n",
      "rank of t: 1\n",
      "shape of t: (7,)\n",
      "0.0 1.0 6.0\n",
      "[2. 3. 4.] [4. 5.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "t= np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)\n",
    "print('rank of t:',t.ndim)\n",
    "print('shape of t:', t.shape)\n",
    "print(t[0],t[1],t[-1])\n",
    "print(t[2:5],t[4:-1])\n",
    "print(t[:2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 11]]\n",
      "2\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "t= np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,11]])\n",
    "print(t)\n",
    "print(t.ndim)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(5.)\n",
      "tensor([2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t.dim())\n",
    "print(t.shape)\n",
    "print(t.size())\n",
    "print(t[0],t[1],t[-2])\n",
    "print(t[2:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 11.]])\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[10,11,11]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())\n",
    "print(t.size())\n",
    "print(t[:,1])\n",
    "print(t[:,1].size())\n",
    "print(t[:,:-1])\n",
    "print(t[:,:-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "m1= torch.FloatTensor([[3,3]])\n",
    "m2= torch.FloatTensor([[2,2]])\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "m1= torch.FloatTensor([[1,2]])\n",
    "m2= torch.FloatTensor([3])#3 ->[[3,3]]\n",
    "print(m1+m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2]]) #1*2가 2*2로 늘어남\n",
    "m2= torch.FloatTensor([[3],[4]]) #2*1이 2*2로 늘어남\n",
    "print(m1+m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul vs matmul\n",
      "matmul\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "mul\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print('mul vs matmul')\n",
    "m1= torch.FloatTensor([[1,2],[3,4]])\n",
    "m2= torch.FloatTensor([[1],[2]])\n",
    "print('matmul')#우리가 아는 행렬곱\n",
    "print(m1.matmul(m2))\n",
    "print('mul')#둘이 사이즈 맞추기 위해 broadcasting 함 즉 m2가 2*2로 브로드캐스팅 \n",
    "print(m1.mul(m2))\n",
    "print(m1*m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([1,2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t= torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max=말그대로 and argmax=인덱스값\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "max: tensor([3., 4.])\n",
      "argmax: tensor([1, 1])\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "max: tensor([2., 4.])\n",
      "argmax: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print('max=말그대로 and argmax=인덱스값')\n",
    "t= torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print(t.max())\n",
    "print(t.max(dim=0))#각값의 인덱스도 같이 반환\n",
    "print('max:', t.max(dim=0)[0])\n",
    "print('argmax:',t.max(dim=0)[1])\n",
    "\n",
    "print(t.max(dim=1))\n",
    "print('max:', t.max(dim=1)[0])\n",
    "print('argmax:',t.max(dim=1)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t= np.array([[[0,1,2],[3,4,5]],[[6,7,8],[9,10,11]]])\n",
    "ft= torch.FloatTensor(t)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n"
     ]
    }
   ],
   "source": [
    "#view 함수는 텐서의 형태를 바꾸는 함수\n",
    "print(ft.view([-1,3]))#2*2*3 ->4*3 \n",
    "#-1은 유동적인 값인 것 같음. 나머지 숫자에 따라 바뀌는 듯 위와 같은 상황에서는 두번째 차원이 3으로 정해졌으므로 자동으로 4가 됨\n",
    "print(ft.view([-1,1,3]))#2*2*3 -> 4*1*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#squeeze 함수는 뷰함수와 비슷함. but 디멘션값이 1인 것들을 모두 삭제해줌\n",
    "ft=torch.FloatTensor([[0],[1],[2]])\n",
    "print(ft)\n",
    "print(ft.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "tensor([0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "#squeeze함수는 dim값을 넣어줌으로써 해당 dim에서 1삭제가능\n",
    "print(ft.squeeze(dim=0))#아무것도 변하지 않음. 왜와이 dim=0은 3이니까\n",
    "print(ft.squeeze(dim=1))#dim=1은 1이라 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "ft=torch.FloatTensor([[0,1,2],[3,4,5]])\n",
    "print(ft)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.]]])\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze함수는 원하는 디멘션값을 입력하면 그 자리에 1을 넣어줌. 디멘션값이 -1은 마지막 디멘션을 의미함. 리스트랑 비슷함.\n",
    "print(ft.unsqueeze(0))\n",
    "print(ft.unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2.]],\n",
      "\n",
      "        [[3., 4., 5.]]])\n",
      "torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(1))\n",
    "print(ft.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.],\n",
      "         [1.],\n",
      "         [2.]],\n",
      "\n",
      "        [[3.],\n",
      "         [4.],\n",
      "         [5.]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(ft.unsqueeze(-1))\n",
    "print(ft.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1., 2., 3., 4.])\n"
     ]
    }
   ],
   "source": [
    "#텐서를 타입캐스팅할 수 있음\n",
    "lt=torch.LongTensor([1,2,3,4])\n",
    "print(lt)\n",
    "print(lt.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "bt=torch.ByteTensor([True,False,True,False])\n",
    "print(bt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0])\n",
      "tensor([1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(bt.long())\n",
    "print(bt.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "#concatenate 이어붙이기\n",
    "x=torch.FloatTensor([[1,2],[3,4]])\n",
    "y=torch.FloatTensor([[5,6],[7,8]])\n",
    "print(torch.cat([x,y],dim=0))#열로 갖다붙이기\n",
    "print(torch.cat([x,y],dim=1))#행으로 갖다붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#stacking함수 \n",
    "x=torch.FloatTensor([1,4])\n",
    "y=torch.FloatTensor([2,5])\n",
    "z=torch.FloatTensor([3,6])\n",
    "print(torch.stack([x,y,z]))\n",
    "print(torch.stack([x,y,z],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#위코드를 concatenate와 unsqueeze를 이용해서 구현하면\n",
    "print(torch.cat([x.unsqueeze(0),y.unsqueeze(0),z.unsqueeze(0)],dim=0))\n",
    "#unsqueeze를 이용해 벡터였던 xyz를 행렬로 만들고 쌓아줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#ones and zeros 전부 0혹은 1로 채움\n",
    "x=torch.FloatTensor([[0,1,2],[2,1,0]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones_like(x))\n",
    "print(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 4.],\n",
      "        [4., 2., 0.]])\n",
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n",
      "\n",
      "tensor([[0., 2., 4.],\n",
      "        [4., 2., 0.]])\n",
      "tensor([[0., 2., 4.],\n",
      "        [4., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#in_place operation 새로운 메모리에 할당하지 않고 기존 값에 반영함\n",
    "print(x.mul(2.))\n",
    "print(x,end='\\n\\n')\n",
    "print(x.mul_(2.))\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "152fa9055cb5915be2de7d146b090e6821134620912f91daec7e1f67fbf8fe74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
